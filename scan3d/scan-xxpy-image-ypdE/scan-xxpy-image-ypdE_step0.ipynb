{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129c3f1b-a272-46e8-ba26-2c814b431d6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59b23d-84b7-40f9-8dfd-46d6dd939e37",
   "metadata": {},
   "source": [
    "* Read the h5 file containing the scan data.\n",
    "* Make sure the scan went as expected.\n",
    "* Process the camera images.\n",
    "    * Threshold \n",
    "    * Downscale\n",
    "    * Crop\n",
    "* Create a new h5 file with separate scalar (0D), waveform (1D), and image (2D) data sets. The new file name is \"prepoc-\" + the original file name.\n",
    "* Save useful information to pass to future notebooks; e.g., slit limits/correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5f5bf-a777-4cbf-a9c7-02547a5191fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import skimage\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import proplot as pplt\n",
    "\n",
    "sys.path.append('../..')\n",
    "from tools import energyVS06 as energy\n",
    "from tools import image_processing as ip\n",
    "from tools import plotting as mplt\n",
    "from tools import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc9335-4d1a-4afb-bded-f1b825effecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pplt.rc['cmap.discrete'] = False\n",
    "pplt.rc['cmap.sequential'] = 'viridis'\n",
    "pplt.rc['grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b179c-eda3-4948-b22d-a278a80c7bb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba5406-86d1-438f-a07b-3483f031064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Diagnostics/Data/Measurements/scan-xxpy-image-ypdE/2022-04-29/'\n",
    "filenames = os.listdir(datadir)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e62cbf-eab6-4a0b-ae3d-f90a5e8c4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '220429190854-scan-xxpy-image-ypdE'\n",
    "file = h5py.File(join(datadir, filename + '.h5'), 'r')\n",
    "print(list(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdaa7f6-63e9-4c2a-a9e2-e252d3d28794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'config' in file:\n",
    "    config = file['config']\n",
    "    print(f\"'config', {type(config)}\")\n",
    "    for key in config:\n",
    "        print(f\"  '{key}', {type(config[key])}\")\n",
    "        for name in config[key].dtype.names:\n",
    "            print(f'    {name}: {config[key][name]}')\n",
    "    # Make dictionary of metadata\n",
    "    metadata = dict()\n",
    "    for name in config['metadata'].dtype.names:\n",
    "        metadata[name] = config['metadata'][name]\n",
    "else:\n",
    "    # Older measurement; metadata is in json file.\n",
    "    metadata = json.load(open(join(datadir, filename + '-metadata.json'), 'r'))\n",
    "    _metadata = dict()\n",
    "    for _dict in metadata.values():\n",
    "        for key, value in _dict.items():\n",
    "            _metadata[key] = value\n",
    "    metadata = _metadata\n",
    "    pprint(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87aa23-3ec7-4eb1-a560-50fb2b9a4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'log' in file:\n",
    "    log = file['log']\n",
    "    print(f\"'log', {type(log)}\")\n",
    "    for item in log.dtype.fields.items():\n",
    "        print('  ', item)\n",
    "\n",
    "    print('\\nErrors and warnings:')\n",
    "    for i in range(log.size):\n",
    "        if not(log[i, 'level'] == 'INFO'.encode('utf')):\n",
    "            timestr = datetime.fromtimestamp(log[i, 'timestamp']).strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "            print(f\"{timestr} {log[i, 'message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b3a9c-17ed-4da2-ae99-c06c310c0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file['scandata']\n",
    "\n",
    "print(f\"'scandata', {type(data)}\")\n",
    "for item in data.dtype.fields.items():\n",
    "    print('  ', item)\n",
    "print(f\"nbytes = {data.nbytes:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432abe0-1346-4f84-bbc9-c8cffb1690ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = ['y_PositionSync', 'xp_PositionSync', 'x_PositionSync']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d91ca-1737-4840-a1ad-7c47bd123359",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dict()  # to pass info between notebooks\n",
    "info['acts'] = acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780a330-f270-4bd1-8d6a-ebe3ecb7de16",
   "metadata": {},
   "source": [
    "## Scan overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fdf82-7fba-486a-8959-7dc820112d40",
   "metadata": {},
   "source": [
    "### Scan volume "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad257c10-8749-4c15-82af-c03fdffbb9b0",
   "metadata": {},
   "source": [
    "Input the min/max slit coordinates, shearing matrix, and boundary (box, ellipsoid) here. These will be used in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c31f1-5165-41d1-8501-c349daf1612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slit ranges, steps, and limits\n",
    "ndim = 3\n",
    "slit_dict = {\n",
    "    'y1': {\n",
    "        'pvname': 'ITSF_Diag:Slit_HZ04',\n",
    "        'center': 13.5,\n",
    "        'distance': 25.0,\n",
    "        'steps': 64,\n",
    "        'min': -50.0,\n",
    "        'max': +50.0,\n",
    "    },\n",
    "    'x2': {\n",
    "        'pvname': 'ITSF_Diag:Slit_VT06',\n",
    "        'center': 13.25,\n",
    "        'distance': 15.0,\n",
    "        'steps': 64,\n",
    "        'min': +4.0,\n",
    "        'max': +22.5,\n",
    "    },\n",
    "    'x1': {\n",
    "        'pvname': 'ITSF_Diag:Slit_VT04',\n",
    "        'center': 12.5,\n",
    "        'distance': 15.0,\n",
    "        'steps': 64,\n",
    "        'min': -50.0, \n",
    "        'max': +50.0,\n",
    "    },\n",
    "}\n",
    "keys = list(slit_dict)\n",
    "M = np.identity(ndim)\n",
    "M[keys.index('x1'), keys.index('x2')] = 0.0  \n",
    "M[keys.index('x2'), keys.index('x1')] = 0.65\n",
    "\n",
    "# Scan boundary\n",
    "boundary = None  # {None, 'ellipsoid'}\n",
    "\n",
    "# Save to info dict\n",
    "info['slit_dict'] = slit_dict\n",
    "info['M'] = M\n",
    "info['ndim'] = ndim\n",
    "info['boundary'] = boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b7cb3-cef1-4d25-8d3c-0302c060e097",
   "metadata": {},
   "source": [
    "### Data collection frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ba029-4c33-4796-a14f-b64c90abe7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = data[-1, 'timestamp'] - data[0, 'timestamp']\n",
    "iteration_duration = duration / data[-1, 'iteration']\n",
    "points_per_iteration = len(data) / data[-1, 'iteration']\n",
    "print(f'{len(data)} points recorded over {duration:.1f} seconds ({(duration / 3600.0):.1f} hours)')\n",
    "print(f\"Number of iterations: {data[-1, 'iteration']}\")\n",
    "print(f'Effective rep rate: {(len(data) / duration):.2f} Hz')\n",
    "print(f'Time per iteration: {iteration_duration:.2f} seconds')\n",
    "print(f'Points per iteration: {points_per_iteration:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531441c7-849d-473b-a3af-af3dc05649fd",
   "metadata": {},
   "source": [
    "Look for long pauses during data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832434a2-6c56-48db-8182-1a7cb1ace456",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.diff(data[:, 'timestamp'])\n",
    "rep_rate = 1.0 / np.median(dt)\n",
    "print(f'reprate = {rep_rate:.2f} Hz')\n",
    "\n",
    "print('Pauses longer than 30 seconds:')\n",
    "long_pause = 30.0\n",
    "print(dt[dt > long_pause])\n",
    "dt[dt > long_pause] = 0.2\n",
    "\n",
    "hist, bins = np.histogram(dt, bins=21)\n",
    "idx_bins = np.digitize(dt, bins)\n",
    "idx_pause, = np.where(idx_bins > 1)\n",
    "median_pause = np.median(dt[idx_pause])\n",
    "print(f'Most pauses are {median_pause:.2f} seconds')\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.bar(0.5 * (bins[1:] + bins[:-1]), hist, color='black', alpha=0.3)\n",
    "ax.axvline(median_pause, color='black')\n",
    "ax.format(xlabel='Pause length [seconds]', ylabel='Number of points', yscale='log')\n",
    "plt.savefig('_output/pauses.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af2a79-a72a-47d4-8ed6-23414b203d1c",
   "metadata": {},
   "source": [
    "### Measured beam current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0eec02-6bee-437c-9c8b-3df89862ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm = 'bcm04'\n",
    "bcm_limit = 20.0  # [mA]\n",
    "bcm_data = np.copy(data[bcm])\n",
    "\n",
    "idx = np.arange(len(data))\n",
    "idx_mask, = np.where(data[bcm] > -bcm_limit)\n",
    "idx_valid, = np.where(~np.isin(idx, idx_mask))\n",
    "\n",
    "print(f'Average BCM current (before masking) = {np.mean(bcm_data):.3f} +- {np.std(bcm_data):.3f} [mA]')\n",
    "for i in idx_mask:\n",
    "    print(f'Point {i} masked due to {bcm} current < {bcm_limit:.3f} [mA]')\n",
    "print(f'Average BCM current (after masking) = {np.mean(bcm_data[idx_valid]):.3f} +- {np.std(bcm_data[idx_valid]):.3f} [mA]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7324e67-4df7-459a-8971-78c4fa44b7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(figsize=(7.0, 2.0))\n",
    "ax.plot(bcm_data[idx], color='black')\n",
    "ax.plot(idx_mask, bcm_data[idx_mask], color='red', lw=0, marker='.', label='Masked')\n",
    "ax.format(xlabel='Point', ylabel='BCM current [mA]', ygrid=True)\n",
    "ax.legend(loc='upper left')\n",
    "plt.savefig('_output/bcm_mask.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a19f5-7460-405b-88cc-7a34fcdbdca5",
   "metadata": {},
   "source": [
    "### Slit positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed5cd4-854c-459d-920d-d70faaac28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for act in acts:\n",
    "    fig, ax = pplt.subplots(figsize=(7.0, 2.0))\n",
    "    ax.plot(idx, data[idx, act], color='black')\n",
    "    ax.plot(idx_mask, data[idx_mask, act], color='red', lw=0, marker='.', label='Masked')\n",
    "    ax.format(xlabel='Point', ylabel=act, ygrid=True)\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.savefig('_output/acts_mask.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611f621-6380-4eb8-ade4-a04d99f4607c",
   "metadata": {},
   "source": [
    "### Iteration numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f472d-e027-482b-a331-b5d9648dd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = pplt.subplots(figsize=(7, 2))\n",
    "# ax.plot(data['iteration'], color='black')\n",
    "# ax.format(xlabel='Step', ylabel='Iteration #')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224c64c-9b70-441a-8e7f-b8f3011eef5f",
   "metadata": {},
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd4e2f-ecb1-4a3d-ab4f-1dc9cc8a3be4",
   "metadata": {},
   "source": [
    "Get the camera name and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff80bc4-ec8a-4fc9-9d80-cd9236e4b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find camera name.\n",
    "cam = None\n",
    "for name in data.dtype.names:\n",
    "    if 'cam' in name.lower():\n",
    "        cam = name.split('_')[0]\n",
    "        \n",
    "# # Find camera zoom. (This doesn't seem to work... is 'Magn' PV is not\n",
    "# # zoom I guess?\n",
    "# zoom = 1.0\n",
    "# for key in metadata:\n",
    "#     if 'Magn' in key:\n",
    "#         zoom = 1.0 / float(metadata[key])\n",
    "zoom = 0.33\n",
    "        \n",
    "# Load camera settings.\n",
    "cam_settings = ip.camera_settings(cam)\n",
    "cam_settings.set_zoom(zoom)\n",
    "\n",
    "# Save info.\n",
    "info['cam'] = cam_settings.name\n",
    "info['cam_zoom'] = cam_settings.zoom\n",
    "info['cam_pix2mm'] = cam_settings.pix2mm\n",
    "info['cam_shape'] = cam_settings.shape\n",
    "\n",
    "print(f\"cam = '{cam}'\")\n",
    "print(f'zoom = {zoom}')\n",
    "print(f'pix2mm = {cam_settings.pix2mm} (zoom = {zoom})')\n",
    "print(f'image shape = {cam_settings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203ba71-dfa3-4cd4-8b3b-88662711eab1",
   "metadata": {},
   "source": [
    "Check out camera integral during the scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebbb92-5e36-4717-abff-f8454e7ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = data[:, cam + '_Integral'].copy()\n",
    "saturation = data[:, cam + '_Saturation'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1b900-0b72-49e6-adfe-e17acdcecf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pplt.subplots(figsize=(10, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d1c9d-3968-458d-bde9-c2651ed9b56b",
   "metadata": {},
   "source": [
    "Use the image with the peak camera integral for testing image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70ad30-4813-45ee-8ae6-00edc1b4ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "imax = np.argmax(data[cam + '_Integral'])\n",
    "imin = np.argmin(data[cam + '_Integral'])\n",
    "print(f'Max {cam} integral at i = {imax}')\n",
    "print(f'Min {cam} integral at i = {imin}')\n",
    "\n",
    "fig, axes = pplt.subplots(nrows=2, figsize=(7, 3.5), spany=False)\n",
    "for ax, param in zip(axes, ['Integral', 'Saturation']):\n",
    "    name = cam + '_' + param\n",
    "    ax.scatter(data[name], color='black', alpha=0.5, ec='None', s=2)\n",
    "    ax.scatter(imax, data[imax, name], color='red', s=3)\n",
    "    ax.format(ylabel=param, xlabel='Point')\n",
    "plt.savefig('_output/integral.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab4759-a8ca-4a6d-8819-2384b1eb17c8",
   "metadata": {},
   "source": [
    "Use the images with the largest/smallest integral for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4be786-774f-40d5-88b3-576b9db71b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(i):\n",
    "    return data[i, cam + '_Image'].reshape(cam_settings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b72e7-4f46-476b-abd5-202c64e88793",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_max = get_image(imax)\n",
    "im_min = get_image(imin)\n",
    "\n",
    "for im, title in zip((im_max, im_min), ('Max integral', 'Min integral')):\n",
    "    fig, axes = pplt.subplots(ncols=2)\n",
    "    kws = dict(colorbar=True)\n",
    "    mplt.plot_image(im.T, ax=axes[0], **kws)\n",
    "    mplt.plot_image(im.T, ax=axes[1], norm='log', **kws)\n",
    "    axes.format(xlabel='x3', ylabel='y3', suptitle=title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5c906-8b67-4ab9-98b5-fd49825e121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_images(im1, im2, **plot_kws):\n",
    "    \"\"\"Plot images side by side, and a second row in log scale.\"\"\"\n",
    "    fig, axes = pplt.subplots(ncols=2, nrows=2, figwidth=None, sharex=False, sharey=False)\n",
    "    for col, im in enumerate([im1, im2]):\n",
    "        for row, norm in enumerate([None, 'log']):\n",
    "            mplt.plot_image(im.T / np.max(im), ax=axes[row, col], norm=norm, **plot_kws)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aca842-9b63-4b43-b5b9-569c24b33c7a",
   "metadata": {},
   "source": [
    "### Denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1ecfc-2fa8-452d-8cc0-7d170819cee5",
   "metadata": {},
   "source": [
    "#### Background subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d48c83-0e06-477f-8eac-4d51aeb3dbdd",
   "metadata": {},
   "source": [
    "Sometimes there is a constant pixel offset in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb0452-b3fb-429d-865c-93a861ddd81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "frames = list(range(imin - n, imin + n, 1))\n",
    "min_pixels = [np.min(get_image(i)) for i in tqdm(frames)]\n",
    "\n",
    "fig, ax = pplt.subplots()\n",
    "ax.plot(frames, min_pixels, color='black', alpha=0.2)\n",
    "ax.format(xlabel='Frame', ylabel='min_pixel')\n",
    "plt.savefig('_output/offset.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c032495-01d2-46b3-9458-f3b771f06351",
   "metadata": {},
   "source": [
    "Remember this offset and subtract it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2bcb1-9b1f-4414-834d-7473fc20e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_offset = np.min(min_pixels)\n",
    "print(f'image_offset = {image_offset}')\n",
    "info['image_offset'] = image_offset\n",
    "\n",
    "im = im_max.copy()\n",
    "im = im - image_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ba57e-d3b9-4349-baf0-543b90a46e80",
   "metadata": {},
   "source": [
    "#### Threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953995b-5f66-44db-9ad2-b5e5059d2d96",
   "metadata": {},
   "source": [
    "We should at least threshold enough to cover noise. Make sure the selected frames are only measuring noise: tune `width_view` to view more frames; tune `width_avg` to select the frames to average over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928509d-b714-450f-8e5f-24044d902958",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = data[:, cam + '_Integral'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb3571-2bf8-4321-b01e-1471e6ffc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_view = 30 * slit_dict['y1']['steps']\n",
    "width_avg = 3 * slit_dict['y1']['steps']\n",
    "\n",
    "idx_view = list(range(imin - width_view, imin + width_view, 1))\n",
    "idx_avg = list(range(imin - width_avg, imin + width_avg, 1))\n",
    "\n",
    "fig, ax = pplt.subplots(figsize=(8.0, 1.25))\n",
    "ax.plot(idx_view, signal[idx_view], color='black', alpha=0.2)\n",
    "ax.plot(idx_avg, signal[idx_avg], color='black', label='to average')\n",
    "ax.legend(loc='upper right')\n",
    "plt.savefig('_output/noise_region.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf4040-57d5-40a6-9c1c-6c439ef21769",
   "metadata": {},
   "source": [
    "Look at the images with the background subtracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946c250-659b-4c81-a806-36b21338ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_noise = np.array([get_image(i) for i in idx_avg])\n",
    "print(f'max noise: {np.max(ims_noise)}')\n",
    "print(f'min noise: {np.min(ims_noise)}')\n",
    "print(f'mean noise: {np.mean(ims_noise)}')\n",
    "print(f'std noise: {np.std(ims_noise)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c4161-a5d2-4f4a-8c2d-f4bc307680e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.9 * (np.max(ims_noise) - image_offset)\n",
    "thresh_frac_peak = thresh / (np.max(im) - image_offset)\n",
    "\n",
    "im1 = im.copy()\n",
    "im1[im1 < thresh] = 0\n",
    "info['image_thresh'] = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963e585-7952-4c40-a72b-cd72118b4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plot_compare_images(im, im1, colorbar=True)\n",
    "axes.format(suptitle=f'Threshold at 10^{np.log10(thresh_frac_peak):.2f} of peak')\n",
    "plt.savefig('_output/thresh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4220094-537e-4770-ad0f-b32fc1c2666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = np.unravel_index(np.argmax(im), im.shape)\n",
    "fig, axes = pplt.subplots([[1, 2, 3], [1, 4, 5]], sharey=False)\n",
    "axes[0].pcolormesh(im)\n",
    "kws = dict(color='white', alpha=0.4)\n",
    "axes[0].axhline(i, **kws)\n",
    "axes[0].axvline(j, **kws)\n",
    "axes[1].set_title(f'Row {i}')\n",
    "axes[2].set_title(f'Column {j}')\n",
    "kws = dict(color='black', lw=1.0)\n",
    "for ax in axes[:, 1]:\n",
    "    ax.plot(np.arange(im.shape[1]), im[i, :] / np.max(im[i, :]), **kws)\n",
    "    ax.axhline(thresh / np.max(im[i, :]), color='black', alpha=0.1)\n",
    "for ax in axes[:, 2]:\n",
    "    ax.plot(np.arange(im.shape[0]), im[:, j] / np.max(im[:, j]), **kws)\n",
    "    ax.axhline(thresh / np.max(im[:, j]), color='black', alpha=0.1)\n",
    "axes[1:, 1].format(yscale='log')\n",
    "plt.savefig('_output/thresh2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57bfc2-b180-4262-864c-8d7bb511b5da",
   "metadata": {},
   "source": [
    "### Downscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cabb6-5de0-44ca-9562-271d34efa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353d339-975a-4a21-b6f1-13458f2307cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_factor = 3\n",
    "info['image_downscale'] = downscale_factor\n",
    "\n",
    "im1 = im.copy()\n",
    "if downscale_factor > 1:\n",
    "    im1 = skimage.transform.downscale_local_mean(\n",
    "        im, (downscale_factor, downscale_factor)\n",
    "    )\n",
    "\n",
    "axes = plot_compare_images(im / np.max(im), im1 / np.max(im1), colorbar=True)\n",
    "axes.format(toplabels=['Original', f'Downscaled by factor {downscale_factor}'])\n",
    "plt.savefig('_output/downscale.png')\n",
    "print(im.shape, im1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6c23b-b0e6-48ac-a088-4ce1590c802c",
   "metadata": {},
   "source": [
    "### Crop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba4c25-fdf5-407a-b3db-5ec73859ee77",
   "metadata": {},
   "source": [
    "If the camera is zoomed out, it is necessary to crop the image to get rid of reflections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6e9d6-6271-42eb-8f56-aa90837fdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a596f9-1afd-4413-b0d0-b83c478ff82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = (np.array([135, -90]) / downscale_factor).astype(int)\n",
    "y1, y2 = (np.array([135, -85]) / downscale_factor).astype(int)\n",
    "# y1, y2 = (10, im.shape[0] - 10)\n",
    "# x1, x2 = (15, im.shape[1] - 15)\n",
    "image_crop_edges = dict(x1=x1, x2=x2, y1=y1, y2=y2)\n",
    "im1 = ip.crop(im, **image_crop_edges)\n",
    "\n",
    "axes = plot_compare_images(im, im1, colorbar=True)\n",
    "for ax in axes[:, 0]:\n",
    "    ax.add_patch(patches.Rectangle((x1, y1), im1.shape[1], im1.shape[0], fill=False, ec='red'))\n",
    "plt.savefig('_output/crop.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dea95f-5f85-4275-9f12-a353558168f7",
   "metadata": {},
   "source": [
    "Make sure that nothing important is cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a67f31-308b-4f5b-8465-28ffed8ad710",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = skimage.transform.downscale_local_mean(data[cam + '_ProfileX'], (1, downscale_factor))\n",
    "py = skimage.transform.downscale_local_mean(data[cam + '_ProfileY'], (1, downscale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864253b-1bc1-40bd-8108-51cdc6660bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pplt.subplots(nrows=2, ncols=2, figsize=(6, 3.5), sharey=1)\n",
    "for j in range(2):\n",
    "    for ax, func in zip(axes[:, j], [np.mean, np.max]):\n",
    "        for p, label in zip([px, py], ['x', 'y']):\n",
    "            f = func(p, axis=0)\n",
    "            ax.plot(np.arange(p.shape[1]), func(p, axis=0), label=label)\n",
    "axes[0, 1].legend(ncols=1, loc='r')\n",
    "\n",
    "colors = pplt.Cycle('colorblind').by_key()['color']\n",
    "for _x1, _x2, _xmax, c in zip([x1, y1], [x2, y2], [px.shape[1], py.shape[1]], colors):\n",
    "    if _x2 < 0:\n",
    "        _x2 += _xmax\n",
    "    for ax in axes:\n",
    "        ax.axvspan(_x1, _x2, color=c, alpha=0.1)\n",
    "    \n",
    "axes[:, 1].format(yscale='log')\n",
    "axes.format(leftlabels=['Mean', 'Max'], toplabels=['Normal scale', 'Log scale'],\n",
    "            xlabel='Pixel', ylabel='Integrated profile')\n",
    "plt.savefig('_output/crop2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aa559-9cea-49bf-9ebf-59e9cd568b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "info['image_crop_edges'] = image_crop_edges\n",
    "info['image_shape'] = im1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6d4e3-06db-4f1d-9519-1e423fb0c7af",
   "metadata": {},
   "source": [
    "## Write new h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226a065-e822-4ad4-853f-89e337e7abf4",
   "metadata": {},
   "source": [
    "Pass info to future notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cd8ec-b259-4236-878e-44c5711e8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978c20b-fcfc-4dcd-8367-99a3685ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickled dictionary for easy loading.\n",
    "utils.save_pickle('_output/info.pkl', info)\n",
    "\n",
    "# Also save as file for easy viewing.\n",
    "file = open('_output/info.txt', 'w')\n",
    "for key, value in info.items():\n",
    "    file.write(f'{key}: {value}\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a3c34-f5a8-468c-8ac8-1125d0584a23",
   "metadata": {},
   "source": [
    "Create a new h5 file with three data sets: scalar (0d), waveform (1d), and image (2d). First, collect the appropriate dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a76bb-0887-4b45-81b9-3e2f7d06af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im1.copy()\n",
    "attrs = data.dtype.names\n",
    "sc_dtype, sc_attrs = [], list(attrs)\n",
    "print(sc_attrs)\n",
    "wf_dtype, wf_attrs = [], []\n",
    "im_dtype, im_attrs = [], []\n",
    "print('Moving the following columns:')\n",
    "for i in reversed(range(len(attrs))):\n",
    "    attr = attrs[i]\n",
    "    if '_Image' in attr:\n",
    "        sc_attrs.pop(i)\n",
    "        im_attrs.append(attr)\n",
    "        im_dtype.append((attr, data.dtype[attr]))\n",
    "        print(attr)\n",
    "    elif 'Profile' in attr:\n",
    "        sc_attrs.pop(i)\n",
    "        wf_attrs.append(attr)\n",
    "        wf_dtype.append((attr, data.dtype[attr]))\n",
    "        print(attr)\n",
    "    else:\n",
    "        sc_dtype.append((attr, data.dtype[attr]))\n",
    "        \n",
    "sc_dtype = np.dtype(sc_dtype)\n",
    "wf_dtype = np.dtype(wf_dtype)\n",
    "im_dtype = np.dtype(im_dtype)\n",
    "\n",
    "# Override the image dtype. The original images had dtype '<i4', but they\n",
    "# became floats if they were downsized.\n",
    "im_dtype = np.dtype([(cam + '_Image', str(im.dtype), (im.size,))])\n",
    "\n",
    "print('\\nscalars:')\n",
    "print(sc_dtype)\n",
    "print('\\nwaveforms:')\n",
    "print(wf_dtype)\n",
    "print('\\nimage:')\n",
    "print(im_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511bc0e-b28b-4418-a07e-5ea03fe6cdc0",
   "metadata": {},
   "source": [
    "Skip points with slow BCM current (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec832a-8a69-4ba8-b935-3348a7eca1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = len(idx_valid)\n",
    "for i in idx_mask:\n",
    "    print(f'Ignoring point {i} due to {bcm} current < {bcm_limit} [mA]')\n",
    "print(f'Number of valid points: {n_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab3dd3-9bf6-40e5-91f0-06a4ba514984",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = h5py.File(join(datadir, 'preproc-' + filename + '.h5'), 'w')\n",
    "data_sc = writer.create_dataset('scalardata', (n_valid,), dtype=sc_dtype)\n",
    "data_wf = writer.create_dataset('wfdata', (n_valid,), dtype=wf_dtype)\n",
    "data_im = writer.create_dataset('imagedata', (n_valid,), dtype=im_dtype)\n",
    "for i, j in enumerate(tqdm(idx_valid)):\n",
    "    for attr in sc_attrs:\n",
    "        data_sc[i, attr] = data[j, attr]\n",
    "    for attr in wf_attrs:\n",
    "        data_wf[i, attr] = data[j, attr]\n",
    "    for attr in im_attrs:\n",
    "        im = get_image(i)\n",
    "        if image_offset is not None:\n",
    "            im = im - image_offset\n",
    "        im[im < thresh] = 0\n",
    "        if downscale_factor > 1:\n",
    "            im = skimage.transform.downscale_local_mean(\n",
    "                im, (downscale_factor, downscale_factor),\n",
    "            )\n",
    "        im = ip.crop(im, **image_crop_edges)\n",
    "        data_im[i, attr] = im.ravel()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c8844-208d-4ad5-a96e-96757651e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
